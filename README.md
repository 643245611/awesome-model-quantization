# ModelCompression


Code, papers, method about model compression. Welcome to add more.

| Paper                                                        | Tags         | Code Link                                                    | Years |
| ------------------------------------------------------------ | ------------ | ------------------------------------------------------------ | ----- |
| ShiftCNN: Generalized Low-Precision Architecture for Inference of Convolutional Neural Networks | Quantization | https://github.com/Ewenwan/caffe-quant-shiftcnn              | 2017  |
| Towards Accurate Binary Convolutional Neural Network         | Quantization | https://github.com/layog/Accurate-Binary-Convolution-Network | 2017  |
| Two-Step Quantization for Low-bit Neural Networks            | Quantization | None                                                         | 2018  |
| Towards Fast and Energy-Efficient Binarized Neural Network Inference on FPGA | FPGA         | None                                                         | 2018  |
| Deep Learning with Low Precision by Half-wave Gaussian Quantization | Quantization | https://github.com/zhaoweicai/hwgq                           | 2017  |
| Performance Guaranteed Network Acceleration via High-Order Residual Quantization | Quantization | None                                                         | 2017  |
| From Hashing to CNNs: Training Binary Weight Networks via Hashing | Quantization | None                                                         | 2017  |
| INCREMENTAL NETWORK QUANTIZATION: TOWARDS LOSSLESS CNNS WITH LOW-PRECISION WEIGHTS | Quantization | https://github.com/Zhouaojun/Incremental-Network-Quantization | 2017  |
| On-chip Memory Based Binarized Convolutional Deep Neural Network Applying Batch Normalization Free Technique on an FPGA | FPGA         | None                                                         | 2017  |
| PACT: PARAMETERIZED CLIPPING ACTIVATION FOR QUANTIZED NEURAL NETWORKS | Quantization | None                                                         | 2018  |
| XNOR-Net- ImageNet Classification Using Binary Convolutional Neural Networks | Quantization | https://github.com/allenai/XNOR-Net                          | 2016  |
| Binarized Neural Networks: Training Deep Neural Networks with Weights and Activations Constrained to +1 or -1 | Quantization | https://github.com/itayhubara/BinaryNet                      | 2016  |
| BinaryNet: Training Deep Neural Networks with Weights and Activations Constrained to +1 or -1 | Quantization | https://github.com/MatthieuCourbariaux/BinaryNet             | 2016  |
| BinaryConnect- Training Deep Neural Networks with binary weights during propagations | Quantization | https://github.com/MatthieuCourbariaux/BinaryConnect         | 2016  |
| FP-BNN- Binarized neural network on FPGA                     | FPGA         | None                                                         | 2017  |


| Code             | From                                                         | Description                                          |
| ---------------- | ------------------------------------------------------------ | ---------------------------------------------------- |
| PyTorch-Quant.py | https://github.com/Ewenwan/pytorch-playground/blob/master/utee/quant.py | Different quantization methods implement by PyTorch. |
| ZF-Net           | https://support.alpha-data.com/pub/appnotes/cnn/             | An Open Source FPGA CNN Library                      |

| Doc                                               | Description                                          |
| ------------------------------------------------- | ---------------------------------------------------- |
| QuantizationMethods.md                            | Quantization Methods                                 |
| Embedded Deep Learning.md                         | Run BNN in FPGA                                      |
| An Open Source FPGA CNN Library.pdf               | Code: ZF-Net, Doc of An Open Source FPGA CNN Library |
| Accelerating CNN inference on FPGAs- A Survey.pdf | Accelerating CNN inference on FPGAs: A Survey.       |

**Reference** 

[1] https://www.codercto.com/a/30037.html

[2] https://github.com/Ewenwan/MVision/tree/master/CNN/Deep_Compression/

[3] https://github.com/Ewenwan/pytorch-playground/blob/master/utee/quant.py

[4] https://github.com/Ewenwan/MVision/tree/master/CNN/Deep_Compression/quantization

[5] https://mp.weixin.qq.com/s/RsZCTqCKwpnjATUFC8da7g