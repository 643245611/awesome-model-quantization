# Awesome Model Quantization



A list of papers, docs, codes about model quantization. This repo is aimed to provide the info for model quantization research, we are continuously improving the project. Welcome to PR the works (papers, repositories) that are missed by the repo.



## Paper list


### 2020

| Paper                                                        |         Tags         |                             Code                             | Years |
| ------------------------------------------------------------ | :------------------: | :----------------------------------------------------------: | :---: |
| A Novel In-DRAM Accelerator Architecture for Binary Neural Network |       Hardware       |                              --                              | 2020  |
| An Energy-Efficient and High Throughput in-Memory Computing Bit-Cell With Excellent Robustness Under Process Variations for Binary Neural Network |       Hardware       |                              --                              | 2020  |
| BNN Pruning: Pruning Binary Neural Network Guided by Weight Flipping Frequency |     Binarization     |       [Link](https://github.com/PSCLab-ASU/BNNPruning)       | 2020  |
| Compact Hash Code Learning With Binary Deep Neural Network   |     Binarization     |                              --                              | 2020  |
| Compressing deep neural networks on FPGAs to binary and ternary precision with hls4ml |       Hardware       |                              --                              | 2020  |
| End-to-end Learned Image Compression with Fixed Point Weight Quantization | Low-bit Quantization |                              --                              | 2020  |
| Low-bit Quantization Needs Good Distribution                 | Low-bit Quantization |                              --                              | 2020  |
| SIMBA: A Skyrmionic In-Memory Binary Neural Network Accelerator |       Hardware       |                                                              | 2020  |
| Training Binary Neural Networks with Real-to-Binary Convolutions |     Binarization     |    [Link](https://github.com/brais-martinez/real2binary)     | 2020  |
| Training with Quantization Noise for Extreme Model Compression | Low-bit Quantization | [Link](https://github.com/pytorch/fairseq/tree/master/examples/quant_noise) | 2020  |




### 2019

| Paper                                                        | Tags                               |                             Code                             | Years |
| ------------------------------------------------------------ | ---------------------------------- | :----------------------------------------------------------: | ----- |
| Product Engine for Energy-Efficient Execution of Binary Neural Networks Using Resistive Memories | Hardware, Binarization             |                              --                              | 2019  |
| A Systematic Study of Binary Neural Networks' Optimisation   | Binarization                       |                              --                              | 2019  |
| Accurate and Compact Convolutional Neural Networks with Trained Binarization | Binarization                       |                              --                              | 2019  |
| Balanced Circulant Binary Convolutional Networks             | Binarization                       |                              --                              | 2019  |
| Binary Ensemble Neural Network: More Bits per Network or More Networks per Bit? | Binarization                       |                              --                              | 2019  |
| BNN+: Improved Binary Network Training                       | Binarization                       |                              --                              | 2019  |
| Circulant Binary Convolutional Networks: Enhancing the Performance of 1-bit DCNNs with Circulant Back Propagation | Binarization                       |                              --                              | 2019  |
| daBNN: A Super Fast Inference Framework for Binary Neural Networks on ARM devices | Hardware, Binarization             |           [Link](https://github.com/JDAI-CV/dabnn)           | 2019  |
| Deep Binary Reconstruction for Cross-Modal Hashing           | Binarization                       |                              --                              | 2019  |
| Differentiable Soft Quantization: Bridging Full-Precision and Low-Bit Neural Networks | Low-bit Quantization               |                              --                              | 2019  |
| Dual Path Binary Neural Network                              | Binarization                       |                              --                              | 2019  |
| Eyeriss v2: A Flexible Accelerator for Emerging Deep Neural Networks on Mobile Devices | Hardware                           |                              --                              | 2019  |
| Fully Quantized Network for Object Detection                 | Low-bit Quantization               |                              --                              | 2019  |
| Hyperdrive: A Multi-Chip Systolically Scalable Binary-Weight CNN Inference Engine | Hardware                           |                              --                              | 2019  |
| Improved training of binary networks for human pose estimation and image recognition | Binarization                       |                              --                              | 2019  |
| Learning Channel-wise Interactions for Binary Convolutional Neural Networks | Binarization                       |                              --                              | 2019  |
| MetaQuant: Learning to Quantize by Learning to Penetrate Non-differentiable Quantization | Low-bit Quantization               |         [Link](httpsï¼š//github.com/csyhhu/MetaQuant)         | 2019  |
| Proxquant: Quantized neural networks via proximal operators  | Low-bit Quantization, Binarization |       [Link](https://github.com/allenbai01/ProxQuant.)       | 2019  |
| PXNOR: Perturbative Binary Neural Network                    | Binarization                       |           [Link](https://github.com/Apfelin/PXNOR)           | 2019  |
| Quantization Networks                                        | Low-bit Quantization               | [Link](https://github.com/aliyun/ alibabacloud-quantization-networks) | 2019  |
| Recursive Binary Neural Network Training Model for Efficient Usage of On-Chip Memory | Binarization                       |                              --                              | 2019  |
| SeerNet: Predicting Convolutional Neural Network Feature-Map Sparsity through Low-Bit Quantization | Low-bit Quantization               |                              --                              | 2019  |
| Self-Binarizing Networks                                     | Binarization                       |                              --                              | 2019  |
| Towards Unified INT8 Training for Convolutional Neural Network | Low-bit Quantization               |                              --                              | 2019  |
| Training Accurate Binary Neural Networks from Scratch        | Binarization                       |        [Link](https://github.com/hpi-xnor/BMXNet-v2)         | 2019  |
| Using Neuroevolved Binary Neural Networks to solve reinforcement learning environments | Binarization                       |          [Link](https://github.com/rval735/BiSUNA)           | 2019  |
| Xcel-RAM: Accelerating Binary Neural Networks in High-Throughput SRAM Compute Arrays | Hardware                           |                              --                              | 2019  |
| XNOR-Net++: Improved binary neural networks                  | Binarization                       |                              --                              | 2019  |
| An Energy-Efficient Reconfigurable Processor for Binary-and Ternary-Weight Neural Networks With Flexible Data Bit Width | Binarization, Low-bit Quantization |                              --                              | 2019  |



### 2018

| Paper                                                        |     Tags     |                      Code                       | Years |
| ------------------------------------------------------------ | :----------: | :---------------------------------------------: | :---: |
| Two-Step Quantization for Low-bit Neural Networks            | Low-bit Quantization |                       --                        | 2018  |
| Extremely Low Bit Neural Network: Squeeze the Last Bit Out with ADMM | Low-bit Quantization | [Link](http://web.stanford.edu/~boyd/admm.html) | 2018  |
| PACT: PARAMETERIZED CLIPPING ACTIVATION FOR QUANTIZED NEURAL NETWORKS | Low-bit Quantization |                       --                        | 2018  |
| Towards Fast and Energy-Efficient Binarized Neural Network Inference on FPGA | Hardware | -- | 2018 |
| A Main/Subsidiary Network Framework for Simplifying Binary Neural Networks | Binarization | -- | 2018 |
| A Survey of FPGA-based Accelerators for Convolutional Neural Networks | Hardware | -- | 2018 |
| An Energy-Efficient Architecture for Binary Weight Convolutional Neural Networks | Binarization | -- | 2018 |
| Analysis and Implementation of Simple Dynamic Binary Neural Networks | Binarization | -- | 2018 |
| Apprentice: Using Knowledge Distillation Techniques To Improve Low-Precision Network Accuracy | Low-bit Quantization | -- | 2018 |
| BitFlow: Exploiting Vector Parallelism for Binary Neural Networks on CPU | Binarization | -- | 2018 |
| BitStream: Efficient Computing Architecture for Real-Time Low-Power Inference of Binary Neural Networks on CPUs | Binarization, Hardware | -- | 2018 |
| Blended Coarse Gradient Descent for Full Quantization of Deep Neural Networks | Low-bit Quantization, Binarization | -- | 2018 |
| BRein Memory: A Single-Chip Binary/Ternary Reconfigurable in-Memory Deep Neural Network Accelerator Achieving 1.4 TOPS at 0.6 W | Hardware | -- | 2018 |
| FBNA: A Fully Binarized Neural Network Accelerator | Hardware | -- | 2018 |
| FINN-R: An End-to-End Deep-Learning Framework for Fast Exploration of Quantized Neural Networks | Hardware | -- | 2018 |
| Loss-aware Binarization of Deep Networks | Binarization | -- | 2018 |
| ReBNet: Residual Binarized Neural Network | Binarization | [Link](https://github.com/mohaghasemzadeh/ReBNet) | 2018 |
| Model compression via distillation and quantization | Low-bit Quantization | [Link](https://github.com/antspy/quantized_distillation) | 2018 |
| Quantization and Training of Neural Networks for Efficient Integer-Arithmetic-Only Inference | Low-bit Quantization | -- | 2018 |
| Stochastic weights binary neural networks on FPGA | Binarization | -- | 2018 |
| Structured Binary Neural Networks for Accurate Image Classification and Semantic Segmentation | Binarization | -- | 2018 |
| SYQ: Learning Symmetric Quantization For Efficient Deep Neural Networks | Low-bit Quantization | [Link](https://www.github.com/julianfaraone/SYQ) | 2018 |
| Towards Fast and Energy-Efficient Binarized Neural Network Inference on FPGA | Binarization, Hardware | -- | 2018 |
| Training Binary Weight Networks via Semi-Binary Decomposition | Binarization | -- | 2018 |
| Training Competitive Binary Neural Networks from Scratch | Binarization | [Link](https://github.com/hpi-xnor/BMXNet-v2) | 2018 |
| XNOR Neural Engine: A Hardware Accelerator IP for 21.6-fJ/op Binary Neural Network Inference | Hardware | -- | 2018 |




### 2017

| Paper                                                        | Tags         | Code                                                    | Years |
| ------------------------------------------------------------ | :----------: | :----------------------------------------------------------: | :---: |
| Ternary Neural Networks with Fine-Grained Quantization | Low-bit Quantization | -- | 2017 |
| ShiftCNN: Generalized Low-Precision Architecture for Inference of Convolutional Neural Networks | Low-bit Quantization | [Link](https://github.com/Ewenwan/caffe-quant-shiftcnn)              | 2017  |
| Towards Accurate Binary Convolutional Neural Network         | Binarization | [Link](https://github.com/layog/Accurate-Binary-Convolution-Network) | 2017  |
| Deep Learning with Low Precision by Half-wave Gaussian Quantization | Low-bit Quantization | [Link](https://github.com/zhaoweicai/hwgq)                           | 2017  |
| Performance Guaranteed Network Acceleration via High-Order Residual Quantization | Low-bit Quantization | --                                                         | 2017  |
| From Hashing to CNNs: Training Binary Weight Networks via Hashing | Binarization | --                                                         | 2017  |
| INCREMENTAL NETWORK QUANTIZATION: TOWARDS LOSSLESS CNNS WITH LOW-PRECISION WEIGHTS | Low-bit Quantization | [Link](https://github.com/Zhouaojun/Incremental-Network-Quantization) | 2017  |
| Trained Ternary Quantization                                 | Low-bit Quantization | [Link](https://github.com/TropComplique/trained-ternary-quantization) | 2017  |
| On-chip Memory Based Binarized Convolutional Deep Neural Network Applying Batch Normalization Free Technique on an FPGA |   Hardware   |                              --                              | 2017  |
| FP-BNN- Binarized neural network on FPGA                     |   Hardware   |                              --                              | 2017  |

### 2016

| Paper                                                        | Tags         | Code                                                    | Years |
| ------------------------------------------------------------ | :----------: | :----------------------------------------------------------: | :---: |
| Ternary weight networks | Low-bit Quantization | [Link](https://github.com/fengfu-chris/caffe-twns) | 2016 |
| DoReFa-Net: Training Low Bitwidth Convolutional Neural Networks with Low Bitwidth Gradients | Low-bit Quantization | [Link](https://github.com/tensorpack/tensorpack/tree/master/examples/DoReFa-Net) | 2016 |
| XNOR-Net- ImageNet Classification Using Binary Convolutional Neural Networks | Binarization | [Link](https://github.com/allenai/XNOR-Net)                         | 2016  |
| Binarized Neural Networks: Training Deep Neural Networks with Weights and Activations Constrained to +1 or -1 | Binarization | [Link](https://github.com/itayhubara/BinaryNet)                      | 2016  |
| BinaryNet: Training Deep Neural Networks with Weights and Activations Constrained to +1 or -1 | Binarization | [Link](https://github.com/MatthieuCourbariaux/BinaryNet)             | 2016  |

### 2015

| Paper                                                        | Tags         | Code                                                    | Years |
| ------------------------------------------------------------ | :----------: | :----------------------------------------------------------: | :---: |
| Bitwise Neural Networks | Binarization | -- | 2015 |
| BinaryConnect- Training Deep Neural Networks with binary weights during propagations | Binarization | [Link](https://github.com/MatthieuCourbariaux/BinaryConnect)         | 2015  |



## Related Codes

| Code             | From                                                         | Description                                          |
| ---------------- | ------------------------------------------------------------ | ---------------------------------------------------- |
| PyTorch-Quant.py | https://github.com/Ewenwan/pytorch-playground/blob/master/utee/quant.py | Different quantization methods implement by Pytorch. |
| ZF-Net           | https://support.alpha-data.com/pub/appnotes/cnn/             | An Open Source FPGA CNN Library                      |



## Docs 

| Doc                                               | Description                                          |
| ------------------------------------------------- | ---------------------------------------------------- |
| QuantizationMethods.md                            | Quantization Methods                                 |
| Embedded Deep Learning.md                         | Run BNN in FPGA                                      |
| An Open Source FPGA CNN Library.pdf               | Code: ZF-Net, Doc of An Open Source FPGA CNN Library |
| Accelerating CNN inference on FPGAs- A Survey.pdf | Accelerating CNN inference on FPGAs: A Survey.       |



## Our Team

### Members

Ruihao Gong

Haotong Qin

Yifu Ding

Xiangguo Zhang

### Our Work



#### Reference

* https://www.codercto.com/a/30037.html

* https://github.com/Ewenwan/MVision/tree/master/CNN/Deep_Compression/

* https://github.com/Ewenwan/pytorch-playground/blob/master/utee/quant.py

* https://github.com/Ewenwan/MVision/tree/master/CNN/Deep_Compression/quantization

* https://mp.weixin.qq.com/s/RsZCTqCKwpnjATUFC8da7g